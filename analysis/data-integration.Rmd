---
output:
  html_document
bibliography: ../ref.bib
---

# Integrating Datasets

```{r setup, echo=FALSE, results="asis"}
source("workflows/knitr_options.R")
```

## Motivation

Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints.
However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality.
This results in systematic differences in the observed expression in cells from different batches, which we refer to as "batch effects".
Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results.

Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis.
However, existing methods based on linear models [@ritchie2015limma;@leek2012sva] assume that the composition of cell populations are either known or the same across batches.
To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data [@haghverdi2018batch;@butler2018integrating;@lin2019scmerge] that do not require _a priori_ knowledge about the composition of the population.
This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable.

Here, we will demonstrate the application of these methods on two case studies involving PBMCs and pancreatic cells.
We will focus on the method proposed by  @haghverdi2018batch, which is based on the detection of mutual nearest neighbours (MNNs).
The MNN approach does not rely on pre-defined or equal population compositions across batches, only requiring that a subset of the population be shared between batches.

## Simple two batch example

### Setting up the data

We will use two separate 10X Genomics datasets involving PBMCs obtained from different donors.
Each dataset was obtained from the `r Biocpkg("TENxPBMCData")` package and separately subjected to basic processing steps.
Separate processing prior to the batch correction step is more convenient, scalable and (on occasion) more reliable.
For example, outlier-based QC on the cells is more effective when performed within a batch (Chapter ???).
The same can also be said for trend fitting when modelling the mean-variance relationship (Section ???).

```{r, results='asis', echo=FALSE}
extractCached("workflows/tenx-batch-pbmc/3k", "feature-selection",
              c("pbmc3k", "dec3k", "chosen.hvgs"))
```

```{r}
pbmc3k
```

```{r, results='asis', echo=FALSE}
extractCached("workflows/tenx-batch-pbmc/4k", "variance-modelling",
              c("pbmc4k", "dec4k"))
```

```{r}
pbmc4k
```

To prepare for the batch correction:

1. We subset all batches to the common "universe" of features.
In this case, it is straightforward as both batches use Ensembl gene annotation^[As we shall see later, this step can be much, much, much more painful. As is often said, biologists would rather share a toothbrush than nomenclature.].

  ```{r}
  universe <- intersect(rownames(pbmc3k), rownames(pbmc4k))
  length(universe)
  ```

2. We rescale each batch to adjust for differences in sequencing depth between batches.
The `multiBatchNorm()` function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between `SingleCellExperiment` objects.
(Size factors only remove biases between cells _within_ a single batch.)
This improves the quality of the correction by removing one aspect of the technical differences between batches.

```{r}
library(batchelor)
rescaled <- multiBatchNorm(pbmc3k[universe,], pbmc4k[universe,])
pbmc3k <- rescaled[[1]]
pbmc4k <- rescaled[[2]]
```

3. We obtain a single set of features for batch correction by compute the average biological component across all batches.
Here, we take all genes with positive biological components to ensure that all interesting biology is retained.
However, other feature selection strategies described in Chapter ??? are also reasonable.

  ```{r}
  mean.bio <- (dec3k[universe,"bio"] + dec4k[universe,"bio"])/2
  chosen <- universe[mean.bio > 0]
  length(chosen)
  ```

### Performing MNN correction

Consider a cell $a$ in batch $A$, and identify the cells in batch $B$ that are nearest neighbours to $a$ in the expression space defined by the selected features.
Repeat this for a cell $b$ in batch $B$, identifying its nearest neighbours in $A$.
Mutual nearest neighbours are pairs of cells from different batches that belong in each other's set of nearest neighbours.
The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see @haghverdi2018batch for full theoretical details.
Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which can yield batch-corrected values.

The `r Biocpkg("batchelor")` package provides an implementation of the MNN approach via the `fastMNN()` function.
We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in `chosen`.
To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top `d` principal components.
Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space.

```{r}
# Using randomized SVD here, as this is faster than 
# irlba for file-backed matrices.
set.seed(1000101001)
mnn.out <- fastMNN(pbmc3k, pbmc4k, d=50, k=20,
    BSPARAM=BiocSingular::RandomParam(deferred=TRUE))
```

The function returns a `SingleCellExperiment` object containing corrected values for downstream analyses like clustering or visualization.
Each column of `mnn.out` corresponds to a cell in one of the batches, while each row corresponds to an input gene in `chosen`.

```{r}
mnn.out
```

The `batch` field in the column metadata contains a vector specifying the batch of origin of each cell. 

```{r}
head(mnn.out$batch) 
```

The `corrected` matrix in the `reducedDims` slot contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses.

```{r}
dim(reducedDim(mnn.out, "corrected"))
```

The `k` parameter is the most important and specifies the number of nearest neighbours to consider when defining MNN pairs.
This should be interpreted as the minimum frequency of any shared cell type or state in each batch.

- Larger values will improve the precision of the correction by increasing the number of MNN pairs.
- Larger `k` provides some robustness to violations of the assumption that the batch vector is orthogonal to the biological subspace [@haghverdi2018batch], by allowing the neighbour search to ignore biological variation in each batch to identify the correct MNN pairs.
- However, larger `k` can also reduce accuracy by allowing incorrect MNN pairs to form between cells of different types.

We suggest starting with the default `k` and increasing it if one is confident that the same cell types are not adequately merged across batches.
This is better than starting with a large `k` as incorrect merging is much harder to diagnose than insufficient merging.

### Correction diagnostics 

#### Clustering and visualization

We use graph-based clustering on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure.
If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from both batches.
In this particular scenario, we expect that both PBMC populations will contain the same set of cell types, so all clusters should contain contributions from both batches.

```{r}
library(scran)
snn.gr <- buildSNNGraph(mnn.out, use.dimred="corrected")
clusters <- igraph::cluster_walktrap(snn.gr)$membership
tab <- table(Cluster=clusters, Batch=mnn.out$batch)
tab
```

```{r, echo=FALSE}
stopifnot(all(tab>0)) # Check the text above was correct.
```

We can also visualize the corrected coordinates using a $t$-SNE plot (Figure \@ref(fig:tsne-pbmc-corrected)).
The presence of visual clusters containing cells from both batches provides a comforting illusion that the correction was successful.

```{r tsne-pbmc-corrected, fig.cap="$t$-SNE plot of the PBMC datasets after MNN correction. Each point is a cell that is colored according to its batch of origin."}
library(scater)
set.seed(0010101010)
mnn.out <- runTSNE(mnn.out, use_dimred="corrected")

mnn.out$batch <- factor(mnn.out$batch)
plotTSNE(mnn.out, colour_by="batch")
```

Needless to say, the mixing of cells from different batches is not an effective diagnostic when the batches involved actually contain unique cell subpopulations.
If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific population.
For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? 
Or should they be merged together?
We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes "shared" and "unique" populations.

#### Percentage of variance lost

For `fastMNN()`, one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction.
Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. 
This is returned via the `lost.var` field in the metadata of `mnn.out`, which contains a matrix of the variance lost in each batch (column) at each merge step (row).

```{r}
metadata(mnn.out)$merge.info$lost.var
```

Large proportions of lost variance suggest that correction is removing genuine biological heterogeneity.
This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace [@haghverdi2018batch].
In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern.

## Harmony

Harmony provides a unified framework for data visualization, analysis, and interpretation of scRNA-seq data. Included is a method for integrating different batches of scRNA-seq. This produces a new dimension reduction representation, saved as `HARMONY` within the *SingleCellExperiment* object, as shown below. Furthermore, this Harmony embedding can be used to produce a UMAP representation as well:

```{r}
## Combine pbmc3k and pbmc4k datasets into single sce
## Removing mcols needed to let cbind work
p3 <- pbmc3k
p4 <- pbmc4k
mcols(p3) <- mcols(p3)[, -1:-ncol(mcols(p3))]
mcols(p4) <- mcols(p4)[, -1:-ncol(mcols(p4))]
int <- intersect(rownames(p3), rownames(p4))
sce <- cbind(p3[int, ], p4[int, ])
chosen.hvgs <- chosen.hvgs[chosen.hvgs %in% int]
```

```{r}
library(harmony) # devtools::install_github('immunogenomics/harmony')
library(BiocSingular)

## create a new sce for harmony
sce_harmony <- sce

## Add PCA to sce, then run Harmony as its dependent on PCA
sce_harmony <- runPCA(sce_harmony,
                      feature_set = chosen.hvgs,
                      BSPARAM = BiocSingular::IrlbaParam(),
                      BPPARAM = BiocParallel::MulticoreParam())
sce_harmony <- RunHarmony(sce_harmony, group.by.vars = "Sample")

## Calculate UMAP on Harmony embeddings
sce_harmony <- runUMAP(sce_harmony, use_dimred = 'HARMONY')
```


```{r, fig.cap = 'Plot of the first two components of the Harmony embedding (left). UMAP calculated on the Harmony embeddings. (right)'}
p1 <- plotReducedDim(sce_harmony, 'HARMONY', colour_by = 'Sample')
p2 <- plotReducedDim(sce_harmony, 'UMAP', colour_by = 'Sample')
wrap_plots(p1, p2, nrow = 1)
```


## Advanced MNN Workflow

Here we work through a more advanced workflow using MNN as above, but this time walking through the various steps that are otherwise implicit within the `fastMNN()` function. While not always necessary, it may be informative for those interested in the finer details of a batch correction workflow. Note that this follows the 

For more details, we refer to the [`compareSingleCell` vignette](https://github.com/MarioniLab/compareSingleCell/) vignette by Aaron Lun.

<!-- ### Feature Selection -->

<!-- We briefly highlight feature selection within the preprocessing, as the choice of genes used in the integration can have an outsize effect on end result.  -->

<!-- For brevity, here we use the `scran` package to identify the genes with biological coefficients of variation greater than zero, but leave the choice of method up to the reader. Note that, compared to the basic analysis workflow, we use the `multiBlockVar()` function and block on the origin (`pbmc3k` vs `pbmc4k`). This function models the variance of expression in each block separately. -->

<!-- Additionally, we turn off weighting such that each sample contributes equally to the results, regardless of the number of cells per sample. This prevents one condition from biasing the combined statistics.  -->

<!-- For more details, we refer to the [`compareSingleCell` merge](https://github.com/MarioniLab/compareSingleCell/blob/master/vignettes/embryo_merge.Rmd) vignette. -->


```{r}
## create a new sce for advanced mnn
sce_mnn_advanced <- sce
```

<!-- ```{r} -->
<!-- library(scran) -->
<!-- dec <- multiBlockVar(sce_mnn_advanced, block = sce_mnn_advanced$Sample, -->
<!--                      make.tech.trend = TRUE, -->
<!--                      weighted = FALSE) -->

<!-- hvg <- rownames(dec)[dec$bio > 0] -->
<!-- ``` -->

<!-- In this example, we get back `r sum(dec$bio > 0)` genes. -->


<!-- ```{r} -->
<!-- hvg_subset <- hvg[1:1000] -->
<!-- ``` -->

### Dimensionality Reduction

Principal components analyses can be used to both reduce computational work and remove high-dimensional noise, as discussed in the `r Biocpkg("simpleSingleCell", "reads.html#denoising-expression-values-using-pca", "simpleSingleCell vignette")`. 

To accomplish this, the `multiBatchPCA()` function from *scran* ensures that each sample contributes equally to the new coordinate space. For further discussion on this point, see the `r Biocpkg("simpleSingleCell", "batch.html#hierarchical-merging", "simpleSingleCell vignette")` section on hierarchical merging.

We then calculate the number of PCs to retain by comparing the variance explained per principal component versus the technical noise and total variance in the data. This will leave us with a subset of PCA components.

Note that we will use the features selected from the preproprocessing step earlier in this chapter.


```{r}
library(batchelor)
library(BiocSingular) # provide approximate pca via IrlbaParam()

## Calculate PCA by batch
set.seed(1234) # for Random/IrlbaParam backends

## run batchelor version of multiBatchPCA (use :: notation to override namespace)
pcs <- batchelor::multiBatchPCA(sce_mnn_advanced,
                                batch = sce_mnn_advanced$Sample,
                                subset.row = chosen.hvgs,
                                get.variance = TRUE,
                                BSPARAM = BiocSingular::IrlbaParam(),
                                BPPARAM = BiocParallel::MulticoreParam())

## Retain only the top PCs based on variance explained > technical noise
retain <- denoisePCANumber(
    metadata(pcs)$var.explained, # variance explained per PC.
    sum(dec[chosen.hvgs, ]$tech),       # technical noise in subset of genes.
    metadata(pcs)$var.total      # total variance in the data
)

retain
```

From the number of PCs to retain, we can filter the PCs as follows:

```{r}
## Subset PCA number of components up to the number in retain
top_pcs <- map(as.list(pcs), ~ .[, 1:retain])
```

Then, using the retained components as input, we can input them directly into the `fastMNN()` method as follows, and furthermore produce a UMAP representation based on these MNN coordinates:

```{r}
## Calculate MNN coordinates, add into reducedDims
mnn_advanced_out <- batchelor::fastMNN(top_pcs$pbmc3k,
                                       top_pcs$pbmc4k,
                                       pc.input = TRUE)
reducedDim(sce_mnn_advanced, 'MNN') <- mnn_advanced_out$corrected

## Run UMAP on MNN coordinates
sce_mnn_advanced <- runUMAP(sce_mnn_advanced, use_dimred = 'MNN')
```

The MNN coordinates and the UMAP coordinates derived from them are visualized below:

```{r, fig.cap = "Plot of first two MNN coordinates (left). UMAP calculated on the MNN coordinates (right). Colour denotes origin of sample."} 
p1 <- plotReducedDim(sce_mnn_advanced, 'MNN', colour_by = 'Sample')
p2 <- plotReducedDim(sce_mnn_advanced, 'UMAP', colour_by = 'Sample')
wrap_plots(p1, p2, nrow = 1)
```

Comparing to the simpler MNN workflow shown above (which only used the `fastMNN()` function on the barely processed *SingleCellExperiment* class object `sce`), we see that the two results are fairly comparable, differing only by the number of principal components and the selected number of features (here we chose 1000 for computational efficacy; we leave it to the interested reader to explore the results with a larger feature space).


## Naive Method Without Correction

For completeness, we show here the results of performing the correction solely on the gene expression matrix.

```{r}
## create a new sce for naive method
sce_naive <- sce
```

```{r}
## run PCA on only the normalized gene expression data
sce_naive <- runPCA(sce_naive,
                    feature_set = chosen.hvgs,
                    BSPARAM = BiocSingular::IrlbaParam(),
                    BPPARAM = BiocParallel::MulticoreParam())

## Run UMAP on the norm gene exp. derived PCA coordinates - use only top PCs
sce_naive <- runUMAP(sce_naive, use_dimred = 'PCA')

```

```{r, fig.cap = "First two components of PCA calculated directly from the gene expression matrix (left). UMAP calculated on the PCA derived from the normalized gene expression matrix (right)."}
p1 <- plotPCA(sce_naive, colour_by = 'Sample')
p2 <- plotReducedDim(sce_naive, 'UMAP', colour_by = 'Sample')
wrap_plots(p1, p2, nrow = 1)
```

While the PCA looks well integrated, the UMAP representation - which encapsulates a fuller PCA space - distinctly shows the residual batch effect present.


## Limma Batch Correction

The `limma` package, a popular framework for the statistical analysis of RNA-seq, has a function `removeBatchEffect()` which will be used here to correct the normalized expression matrix `logcounts` across the two batches. The result will be assigned into the `assays` slot of the `sce` object as `limma_corrected`, and then used for PCA, saving the result in the `reducedDim` slot as `"PCA_limma"`.

```{r}
## create a new sce for limma method
sce_limma <- sce
```

```{r}
library(limma)
limma_corrected <- removeBatchEffect(logcounts(sce_limma), batch = sce_limma$Sample)
assay(sce_limma, "logcounts_limma") <- limma_corrected ## add new assay

## calc a PCA on limma values; save separate to prevent overwriting
sce_limma <- runPCA(sce_limma,
                    feature_set = chosen.hvgs,
                    exprs_values = "logcounts_limma",
                    BSPARAM = BiocSingular::IrlbaParam(),
                    BPPARAM = BiocParallel::MulticoreParam())

## run UMAP; save separate to prevent overwriting
sce_limma <- runUMAP(sce_limma, use_dimred = 'PCA')
```

The resulting PCA and UMAP from the limma batch correction method are shown below:

```{r, fig.cap = 'PCA calculated on the limma batch-corrected gene expression matrix (left). UMAP calculated via the PCA derived from limma batch-corrected gene expression matrix (right).'}
p1 <- plotReducedDim(sce_limma, 'PCA', colour_by = 'Sample')
p2 <- plotReducedDim(sce_limma, 'UMAP', colour_by = 'Sample')
wrap_plots(p1, p2, nrow = 1)
```


## Session Info

```{r, echo=FALSE}
prettySessionInfo()
```

